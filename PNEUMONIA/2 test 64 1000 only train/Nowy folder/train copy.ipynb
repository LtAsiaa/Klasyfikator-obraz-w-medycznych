{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 1.0749 - accuracy: 0.7275 - val_loss: 1.0472 - val_accuracy: 0.7519\n",
      "Epoch 2/1000\n",
      "66/66 [==============================] - 7s 113ms/step - loss: 1.0260 - accuracy: 0.7407 - val_loss: 1.0006 - val_accuracy: 0.7519\n",
      "Epoch 3/1000\n",
      "66/66 [==============================] - 7s 108ms/step - loss: 0.9831 - accuracy: 0.7407 - val_loss: 0.9590 - val_accuracy: 0.7519\n",
      "Epoch 4/1000\n",
      "66/66 [==============================] - 7s 114ms/step - loss: 0.9448 - accuracy: 0.7407 - val_loss: 0.9220 - val_accuracy: 0.7519\n",
      "Epoch 5/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.9108 - accuracy: 0.7407 - val_loss: 0.8893 - val_accuracy: 0.7519\n",
      "Epoch 6/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.8809 - accuracy: 0.7407 - val_loss: 0.8601 - val_accuracy: 0.7519\n",
      "Epoch 7/1000\n",
      "66/66 [==============================] - 8s 114ms/step - loss: 0.8545 - accuracy: 0.7407 - val_loss: 0.8346 - val_accuracy: 0.7519\n",
      "Epoch 8/1000\n",
      "66/66 [==============================] - 7s 112ms/step - loss: 0.8308 - accuracy: 0.7407 - val_loss: 0.8119 - val_accuracy: 0.7519\n",
      "Epoch 9/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.8101 - accuracy: 0.7407 - val_loss: 0.7919 - val_accuracy: 0.7519\n",
      "Epoch 10/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.7913 - accuracy: 0.7407 - val_loss: 0.7737 - val_accuracy: 0.7519\n",
      "Epoch 11/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.7745 - accuracy: 0.7407 - val_loss: 0.7573 - val_accuracy: 0.7519\n",
      "Epoch 12/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.7595 - accuracy: 0.7407 - val_loss: 0.7427 - val_accuracy: 0.7519\n",
      "Epoch 13/1000\n",
      "66/66 [==============================] - 7s 110ms/step - loss: 0.7461 - accuracy: 0.7407 - val_loss: 0.7296 - val_accuracy: 0.7519\n",
      "Epoch 14/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.7340 - accuracy: 0.7407 - val_loss: 0.7181 - val_accuracy: 0.7519\n",
      "Epoch 15/1000\n",
      "66/66 [==============================] - 7s 110ms/step - loss: 0.7230 - accuracy: 0.7407 - val_loss: 0.7074 - val_accuracy: 0.7519\n",
      "Epoch 16/1000\n",
      "66/66 [==============================] - 7s 111ms/step - loss: 0.7131 - accuracy: 0.7407 - val_loss: 0.6977 - val_accuracy: 0.7519\n",
      "Epoch 17/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.7041 - accuracy: 0.7407 - val_loss: 0.6889 - val_accuracy: 0.7519\n",
      "Epoch 18/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.6959 - accuracy: 0.7407 - val_loss: 0.6810 - val_accuracy: 0.7519\n",
      "Epoch 19/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.6883 - accuracy: 0.7407 - val_loss: 0.6736 - val_accuracy: 0.7519\n",
      "Epoch 20/1000\n",
      "66/66 [==============================] - 10s 153ms/step - loss: 0.6814 - accuracy: 0.7407 - val_loss: 0.6669 - val_accuracy: 0.7519\n",
      "Epoch 21/1000\n",
      "66/66 [==============================] - 10s 151ms/step - loss: 0.6751 - accuracy: 0.7407 - val_loss: 0.6608 - val_accuracy: 0.7519\n",
      "Epoch 22/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.6693 - accuracy: 0.7407 - val_loss: 0.6551 - val_accuracy: 0.7519\n",
      "Epoch 23/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.6639 - accuracy: 0.7407 - val_loss: 0.6498 - val_accuracy: 0.7519\n",
      "Epoch 24/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.6590 - accuracy: 0.7407 - val_loss: 0.6450 - val_accuracy: 0.7519\n",
      "Epoch 25/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.6544 - accuracy: 0.7407 - val_loss: 0.6405 - val_accuracy: 0.7519\n",
      "Epoch 26/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.6502 - accuracy: 0.7407 - val_loss: 0.6364 - val_accuracy: 0.7519\n",
      "Epoch 27/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.6462 - accuracy: 0.7407 - val_loss: 0.6326 - val_accuracy: 0.7519\n",
      "Epoch 28/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.6425 - accuracy: 0.7407 - val_loss: 0.6289 - val_accuracy: 0.7519\n",
      "Epoch 29/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.6391 - accuracy: 0.7407 - val_loss: 0.6256 - val_accuracy: 0.7519\n",
      "Epoch 30/1000\n",
      "66/66 [==============================] - 9s 141ms/step - loss: 0.6359 - accuracy: 0.7407 - val_loss: 0.6225 - val_accuracy: 0.7519\n",
      "Epoch 31/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.6329 - accuracy: 0.7407 - val_loss: 0.6196 - val_accuracy: 0.7519\n",
      "Epoch 32/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.6301 - accuracy: 0.7407 - val_loss: 0.6169 - val_accuracy: 0.7519\n",
      "Epoch 33/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.6275 - accuracy: 0.7407 - val_loss: 0.6143 - val_accuracy: 0.7519\n",
      "Epoch 34/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.6251 - accuracy: 0.7407 - val_loss: 0.6119 - val_accuracy: 0.7519\n",
      "Epoch 35/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.6228 - accuracy: 0.7407 - val_loss: 0.6096 - val_accuracy: 0.7519\n",
      "Epoch 36/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.6206 - accuracy: 0.7407 - val_loss: 0.6075 - val_accuracy: 0.7519\n",
      "Epoch 37/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.6185 - accuracy: 0.7407 - val_loss: 0.6056 - val_accuracy: 0.7519\n",
      "Epoch 38/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.6166 - accuracy: 0.7407 - val_loss: 0.6037 - val_accuracy: 0.7519\n",
      "Epoch 39/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.6148 - accuracy: 0.7407 - val_loss: 0.6019 - val_accuracy: 0.7519\n",
      "Epoch 40/1000\n",
      "66/66 [==============================] - 8s 115ms/step - loss: 0.6130 - accuracy: 0.7407 - val_loss: 0.6002 - val_accuracy: 0.7519\n",
      "Epoch 41/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.6114 - accuracy: 0.7407 - val_loss: 0.5987 - val_accuracy: 0.7519\n",
      "Epoch 42/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.6099 - accuracy: 0.7407 - val_loss: 0.5971 - val_accuracy: 0.7519\n",
      "Epoch 43/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.6084 - accuracy: 0.7407 - val_loss: 0.5957 - val_accuracy: 0.7519\n",
      "Epoch 44/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.6070 - accuracy: 0.7407 - val_loss: 0.5944 - val_accuracy: 0.7519\n",
      "Epoch 45/1000\n",
      "66/66 [==============================] - 8s 114ms/step - loss: 0.6057 - accuracy: 0.7407 - val_loss: 0.5930 - val_accuracy: 0.7519\n",
      "Epoch 46/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.6045 - accuracy: 0.7407 - val_loss: 0.5919 - val_accuracy: 0.7519\n",
      "Epoch 47/1000\n",
      "66/66 [==============================] - 10s 147ms/step - loss: 0.6033 - accuracy: 0.7407 - val_loss: 0.5907 - val_accuracy: 0.7519\n",
      "Epoch 48/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.6022 - accuracy: 0.7407 - val_loss: 0.5896 - val_accuracy: 0.7519\n",
      "Epoch 49/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.6011 - accuracy: 0.7407 - val_loss: 0.5887 - val_accuracy: 0.7519\n",
      "Epoch 50/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.6001 - accuracy: 0.7407 - val_loss: 0.5876 - val_accuracy: 0.7519\n",
      "Epoch 51/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5991 - accuracy: 0.7407 - val_loss: 0.5865 - val_accuracy: 0.7519\n",
      "Epoch 52/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5982 - accuracy: 0.7407 - val_loss: 0.5856 - val_accuracy: 0.7519\n",
      "Epoch 53/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5973 - accuracy: 0.7407 - val_loss: 0.5847 - val_accuracy: 0.7519\n",
      "Epoch 54/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5964 - accuracy: 0.7407 - val_loss: 0.5839 - val_accuracy: 0.7519\n",
      "Epoch 55/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5956 - accuracy: 0.7407 - val_loss: 0.5831 - val_accuracy: 0.7519\n",
      "Epoch 56/1000\n",
      "66/66 [==============================] - 8s 116ms/step - loss: 0.5949 - accuracy: 0.7407 - val_loss: 0.5824 - val_accuracy: 0.7519\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5941 - accuracy: 0.7407 - val_loss: 0.5817 - val_accuracy: 0.7519\n",
      "Epoch 58/1000\n",
      "66/66 [==============================] - 8s 114ms/step - loss: 0.5934 - accuracy: 0.7407 - val_loss: 0.5810 - val_accuracy: 0.7519\n",
      "Epoch 59/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5927 - accuracy: 0.7407 - val_loss: 0.5803 - val_accuracy: 0.7519\n",
      "Epoch 60/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5921 - accuracy: 0.7407 - val_loss: 0.5797 - val_accuracy: 0.7519\n",
      "Epoch 61/1000\n",
      "66/66 [==============================] - 8s 116ms/step - loss: 0.5914 - accuracy: 0.7407 - val_loss: 0.5791 - val_accuracy: 0.7519\n",
      "Epoch 62/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5908 - accuracy: 0.7407 - val_loss: 0.5785 - val_accuracy: 0.7519\n",
      "Epoch 63/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5903 - accuracy: 0.7407 - val_loss: 0.5779 - val_accuracy: 0.7519\n",
      "Epoch 64/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5897 - accuracy: 0.7407 - val_loss: 0.5773 - val_accuracy: 0.7519\n",
      "Epoch 65/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5892 - accuracy: 0.7407 - val_loss: 0.5768 - val_accuracy: 0.7519\n",
      "Epoch 66/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5887 - accuracy: 0.7407 - val_loss: 0.5763 - val_accuracy: 0.7519\n",
      "Epoch 67/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5882 - accuracy: 0.7407 - val_loss: 0.5758 - val_accuracy: 0.7519\n",
      "Epoch 68/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5877 - accuracy: 0.7407 - val_loss: 0.5753 - val_accuracy: 0.7519\n",
      "Epoch 69/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5872 - accuracy: 0.7407 - val_loss: 0.5749 - val_accuracy: 0.7519\n",
      "Epoch 70/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5868 - accuracy: 0.7407 - val_loss: 0.5745 - val_accuracy: 0.7519\n",
      "Epoch 71/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5864 - accuracy: 0.7407 - val_loss: 0.5741 - val_accuracy: 0.7519\n",
      "Epoch 72/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5859 - accuracy: 0.7407 - val_loss: 0.5737 - val_accuracy: 0.7519\n",
      "Epoch 73/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5855 - accuracy: 0.7407 - val_loss: 0.5734 - val_accuracy: 0.7519\n",
      "Epoch 74/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5852 - accuracy: 0.7407 - val_loss: 0.5730 - val_accuracy: 0.7519\n",
      "Epoch 75/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5848 - accuracy: 0.7407 - val_loss: 0.5727 - val_accuracy: 0.7519\n",
      "Epoch 76/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5845 - accuracy: 0.7407 - val_loss: 0.5723 - val_accuracy: 0.7519\n",
      "Epoch 77/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5841 - accuracy: 0.7407 - val_loss: 0.5720 - val_accuracy: 0.7519\n",
      "Epoch 78/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5838 - accuracy: 0.7407 - val_loss: 0.5716 - val_accuracy: 0.7519\n",
      "Epoch 79/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5835 - accuracy: 0.7407 - val_loss: 0.5713 - val_accuracy: 0.7519\n",
      "Epoch 80/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5831 - accuracy: 0.7407 - val_loss: 0.5710 - val_accuracy: 0.7519\n",
      "Epoch 81/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5828 - accuracy: 0.7407 - val_loss: 0.5707 - val_accuracy: 0.7519\n",
      "Epoch 82/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5825 - accuracy: 0.7407 - val_loss: 0.5704 - val_accuracy: 0.7519\n",
      "Epoch 83/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5823 - accuracy: 0.7407 - val_loss: 0.5701 - val_accuracy: 0.7519\n",
      "Epoch 84/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5820 - accuracy: 0.7407 - val_loss: 0.5698 - val_accuracy: 0.7519\n",
      "Epoch 85/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5817 - accuracy: 0.7407 - val_loss: 0.5696 - val_accuracy: 0.7519\n",
      "Epoch 86/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5815 - accuracy: 0.7407 - val_loss: 0.5692 - val_accuracy: 0.7519\n",
      "Epoch 87/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5812 - accuracy: 0.7407 - val_loss: 0.5691 - val_accuracy: 0.7519\n",
      "Epoch 88/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5810 - accuracy: 0.7407 - val_loss: 0.5689 - val_accuracy: 0.7519\n",
      "Epoch 89/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5807 - accuracy: 0.7407 - val_loss: 0.5686 - val_accuracy: 0.7519\n",
      "Epoch 90/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5805 - accuracy: 0.7407 - val_loss: 0.5684 - val_accuracy: 0.7519\n",
      "Epoch 91/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5803 - accuracy: 0.7407 - val_loss: 0.5681 - val_accuracy: 0.7519\n",
      "Epoch 92/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5801 - accuracy: 0.7407 - val_loss: 0.5680 - val_accuracy: 0.7519\n",
      "Epoch 93/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5798 - accuracy: 0.7407 - val_loss: 0.5678 - val_accuracy: 0.7519\n",
      "Epoch 94/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5797 - accuracy: 0.7407 - val_loss: 0.5676 - val_accuracy: 0.7519\n",
      "Epoch 95/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5795 - accuracy: 0.7407 - val_loss: 0.5674 - val_accuracy: 0.7519\n",
      "Epoch 96/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5793 - accuracy: 0.7407 - val_loss: 0.5672 - val_accuracy: 0.7519\n",
      "Epoch 97/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5791 - accuracy: 0.7407 - val_loss: 0.5671 - val_accuracy: 0.7519\n",
      "Epoch 98/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5789 - accuracy: 0.7407 - val_loss: 0.5669 - val_accuracy: 0.7519\n",
      "Epoch 99/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5787 - accuracy: 0.7407 - val_loss: 0.5667 - val_accuracy: 0.7519\n",
      "Epoch 100/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5786 - accuracy: 0.7407 - val_loss: 0.5665 - val_accuracy: 0.7519\n",
      "Epoch 101/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5784 - accuracy: 0.7407 - val_loss: 0.5664 - val_accuracy: 0.7519\n",
      "Epoch 102/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5782 - accuracy: 0.7407 - val_loss: 0.5663 - val_accuracy: 0.7519\n",
      "Epoch 103/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5781 - accuracy: 0.7407 - val_loss: 0.5661 - val_accuracy: 0.7519\n",
      "Epoch 104/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5779 - accuracy: 0.7407 - val_loss: 0.5660 - val_accuracy: 0.7519\n",
      "Epoch 105/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5778 - accuracy: 0.7407 - val_loss: 0.5658 - val_accuracy: 0.7519\n",
      "Epoch 106/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5777 - accuracy: 0.7407 - val_loss: 0.5657 - val_accuracy: 0.7519\n",
      "Epoch 107/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5775 - accuracy: 0.7407 - val_loss: 0.5655 - val_accuracy: 0.7519\n",
      "Epoch 108/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5774 - accuracy: 0.7407 - val_loss: 0.5654 - val_accuracy: 0.7519\n",
      "Epoch 109/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5772 - accuracy: 0.7407 - val_loss: 0.5653 - val_accuracy: 0.7519\n",
      "Epoch 110/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5771 - accuracy: 0.7407 - val_loss: 0.5651 - val_accuracy: 0.7519\n",
      "Epoch 111/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5770 - accuracy: 0.7407 - val_loss: 0.5650 - val_accuracy: 0.7519\n",
      "Epoch 112/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5769 - accuracy: 0.7407 - val_loss: 0.5650 - val_accuracy: 0.7519\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5767 - accuracy: 0.7407 - val_loss: 0.5648 - val_accuracy: 0.7519\n",
      "Epoch 114/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5766 - accuracy: 0.7407 - val_loss: 0.5646 - val_accuracy: 0.7519\n",
      "Epoch 115/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5765 - accuracy: 0.7407 - val_loss: 0.5646 - val_accuracy: 0.7519\n",
      "Epoch 116/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5764 - accuracy: 0.7407 - val_loss: 0.5644 - val_accuracy: 0.7519\n",
      "Epoch 117/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5763 - accuracy: 0.7407 - val_loss: 0.5643 - val_accuracy: 0.7519\n",
      "Epoch 118/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5762 - accuracy: 0.7407 - val_loss: 0.5643 - val_accuracy: 0.7519\n",
      "Epoch 119/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5761 - accuracy: 0.7407 - val_loss: 0.5641 - val_accuracy: 0.7519\n",
      "Epoch 120/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5760 - accuracy: 0.7407 - val_loss: 0.5641 - val_accuracy: 0.7519\n",
      "Epoch 121/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5759 - accuracy: 0.7407 - val_loss: 0.5640 - val_accuracy: 0.7519\n",
      "Epoch 122/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5758 - accuracy: 0.7407 - val_loss: 0.5640 - val_accuracy: 0.7519\n",
      "Epoch 123/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5757 - accuracy: 0.7407 - val_loss: 0.5639 - val_accuracy: 0.7519\n",
      "Epoch 124/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5756 - accuracy: 0.7407 - val_loss: 0.5637 - val_accuracy: 0.7519\n",
      "Epoch 125/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5756 - accuracy: 0.7407 - val_loss: 0.5637 - val_accuracy: 0.7519\n",
      "Epoch 126/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5755 - accuracy: 0.7407 - val_loss: 0.5635 - val_accuracy: 0.7519\n",
      "Epoch 127/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5754 - accuracy: 0.7407 - val_loss: 0.5635 - val_accuracy: 0.7519\n",
      "Epoch 128/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5753 - accuracy: 0.7407 - val_loss: 0.5634 - val_accuracy: 0.7519\n",
      "Epoch 129/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5752 - accuracy: 0.7407 - val_loss: 0.5633 - val_accuracy: 0.7519\n",
      "Epoch 130/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5752 - accuracy: 0.7407 - val_loss: 0.5632 - val_accuracy: 0.7519\n",
      "Epoch 131/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5751 - accuracy: 0.7407 - val_loss: 0.5632 - val_accuracy: 0.7519\n",
      "Epoch 132/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5750 - accuracy: 0.7407 - val_loss: 0.5631 - val_accuracy: 0.7519\n",
      "Epoch 133/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5750 - accuracy: 0.7407 - val_loss: 0.5631 - val_accuracy: 0.7519\n",
      "Epoch 134/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5749 - accuracy: 0.7407 - val_loss: 0.5630 - val_accuracy: 0.7519\n",
      "Epoch 135/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5748 - accuracy: 0.7407 - val_loss: 0.5629 - val_accuracy: 0.7519\n",
      "Epoch 136/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5748 - accuracy: 0.7407 - val_loss: 0.5628 - val_accuracy: 0.7519\n",
      "Epoch 137/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5747 - accuracy: 0.7407 - val_loss: 0.5628 - val_accuracy: 0.7519\n",
      "Epoch 138/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5747 - accuracy: 0.7407 - val_loss: 0.5628 - val_accuracy: 0.7519\n",
      "Epoch 139/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5746 - accuracy: 0.7407 - val_loss: 0.5626 - val_accuracy: 0.7519\n",
      "Epoch 140/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5745 - accuracy: 0.7407 - val_loss: 0.5626 - val_accuracy: 0.7519\n",
      "Epoch 141/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5745 - accuracy: 0.7407 - val_loss: 0.5626 - val_accuracy: 0.7519\n",
      "Epoch 142/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5744 - accuracy: 0.7407 - val_loss: 0.5626 - val_accuracy: 0.7519\n",
      "Epoch 143/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5744 - accuracy: 0.7407 - val_loss: 0.5625 - val_accuracy: 0.7519\n",
      "Epoch 144/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5743 - accuracy: 0.7407 - val_loss: 0.5624 - val_accuracy: 0.7519\n",
      "Epoch 145/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5743 - accuracy: 0.7407 - val_loss: 0.5623 - val_accuracy: 0.7519\n",
      "Epoch 146/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5742 - accuracy: 0.7407 - val_loss: 0.5623 - val_accuracy: 0.7519\n",
      "Epoch 147/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5742 - accuracy: 0.7407 - val_loss: 0.5623 - val_accuracy: 0.7519\n",
      "Epoch 148/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5742 - accuracy: 0.7407 - val_loss: 0.5622 - val_accuracy: 0.7519\n",
      "Epoch 149/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5741 - accuracy: 0.7407 - val_loss: 0.5622 - val_accuracy: 0.7519\n",
      "Epoch 150/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5740 - accuracy: 0.7407 - val_loss: 0.5621 - val_accuracy: 0.7519\n",
      "Epoch 151/1000\n",
      "66/66 [==============================] - 8s 115ms/step - loss: 0.5740 - accuracy: 0.7407 - val_loss: 0.5620 - val_accuracy: 0.7519\n",
      "Epoch 152/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5740 - accuracy: 0.7407 - val_loss: 0.5620 - val_accuracy: 0.7519\n",
      "Epoch 153/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5739 - accuracy: 0.7407 - val_loss: 0.5620 - val_accuracy: 0.7519\n",
      "Epoch 154/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5739 - accuracy: 0.7407 - val_loss: 0.5619 - val_accuracy: 0.7519\n",
      "Epoch 155/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5738 - accuracy: 0.7407 - val_loss: 0.5619 - val_accuracy: 0.7519\n",
      "Epoch 156/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5738 - accuracy: 0.7407 - val_loss: 0.5619 - val_accuracy: 0.7519\n",
      "Epoch 157/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5737 - accuracy: 0.7407 - val_loss: 0.5619 - val_accuracy: 0.7519\n",
      "Epoch 158/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5737 - accuracy: 0.7407 - val_loss: 0.5619 - val_accuracy: 0.7519\n",
      "Epoch 159/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5737 - accuracy: 0.7407 - val_loss: 0.5618 - val_accuracy: 0.7519\n",
      "Epoch 160/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5737 - accuracy: 0.7407 - val_loss: 0.5618 - val_accuracy: 0.7519\n",
      "Epoch 161/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5736 - accuracy: 0.7407 - val_loss: 0.5617 - val_accuracy: 0.7519\n",
      "Epoch 162/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5736 - accuracy: 0.7407 - val_loss: 0.5617 - val_accuracy: 0.7519\n",
      "Epoch 163/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5735 - accuracy: 0.7407 - val_loss: 0.5616 - val_accuracy: 0.7519\n",
      "Epoch 164/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5735 - accuracy: 0.7407 - val_loss: 0.5616 - val_accuracy: 0.7519\n",
      "Epoch 165/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5735 - accuracy: 0.7407 - val_loss: 0.5616 - val_accuracy: 0.7519\n",
      "Epoch 166/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5735 - accuracy: 0.7407 - val_loss: 0.5615 - val_accuracy: 0.7519\n",
      "Epoch 167/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5734 - accuracy: 0.7407 - val_loss: 0.5615 - val_accuracy: 0.7519\n",
      "Epoch 168/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5734 - accuracy: 0.7407 - val_loss: 0.5615 - val_accuracy: 0.7519\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5734 - accuracy: 0.7407 - val_loss: 0.5616 - val_accuracy: 0.7519\n",
      "Epoch 170/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5734 - accuracy: 0.7407 - val_loss: 0.5614 - val_accuracy: 0.7519\n",
      "Epoch 171/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5734 - accuracy: 0.7407 - val_loss: 0.5614 - val_accuracy: 0.7519\n",
      "Epoch 172/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5733 - accuracy: 0.7407 - val_loss: 0.5614 - val_accuracy: 0.7519\n",
      "Epoch 173/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5733 - accuracy: 0.7407 - val_loss: 0.5614 - val_accuracy: 0.7519\n",
      "Epoch 174/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5733 - accuracy: 0.7407 - val_loss: 0.5614 - val_accuracy: 0.7519\n",
      "Epoch 175/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5732 - accuracy: 0.7407 - val_loss: 0.5614 - val_accuracy: 0.7519\n",
      "Epoch 176/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5732 - accuracy: 0.7407 - val_loss: 0.5614 - val_accuracy: 0.7519\n",
      "Epoch 177/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5732 - accuracy: 0.7407 - val_loss: 0.5614 - val_accuracy: 0.7519\n",
      "Epoch 178/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5732 - accuracy: 0.7407 - val_loss: 0.5613 - val_accuracy: 0.7519\n",
      "Epoch 179/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5732 - accuracy: 0.7407 - val_loss: 0.5613 - val_accuracy: 0.7519\n",
      "Epoch 180/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5731 - accuracy: 0.7407 - val_loss: 0.5612 - val_accuracy: 0.7519\n",
      "Epoch 181/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5731 - accuracy: 0.7407 - val_loss: 0.5612 - val_accuracy: 0.7519\n",
      "Epoch 182/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5731 - accuracy: 0.7407 - val_loss: 0.5612 - val_accuracy: 0.7519\n",
      "Epoch 183/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5731 - accuracy: 0.7407 - val_loss: 0.5611 - val_accuracy: 0.7519\n",
      "Epoch 184/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5731 - accuracy: 0.7407 - val_loss: 0.5612 - val_accuracy: 0.7519\n",
      "Epoch 185/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5730 - accuracy: 0.7407 - val_loss: 0.5612 - val_accuracy: 0.7519\n",
      "Epoch 186/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5730 - accuracy: 0.7407 - val_loss: 0.5611 - val_accuracy: 0.7519\n",
      "Epoch 187/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5730 - accuracy: 0.7407 - val_loss: 0.5612 - val_accuracy: 0.7519\n",
      "Epoch 188/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5730 - accuracy: 0.7407 - val_loss: 0.5612 - val_accuracy: 0.7519\n",
      "Epoch 189/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5730 - accuracy: 0.7407 - val_loss: 0.5611 - val_accuracy: 0.7519\n",
      "Epoch 190/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5730 - accuracy: 0.7407 - val_loss: 0.5611 - val_accuracy: 0.7519\n",
      "Epoch 191/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5729 - accuracy: 0.7407 - val_loss: 0.5611 - val_accuracy: 0.7519\n",
      "Epoch 192/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5730 - accuracy: 0.7407 - val_loss: 0.5610 - val_accuracy: 0.7519\n",
      "Epoch 193/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5729 - accuracy: 0.7407 - val_loss: 0.5611 - val_accuracy: 0.7519\n",
      "Epoch 194/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5729 - accuracy: 0.7407 - val_loss: 0.5612 - val_accuracy: 0.7519\n",
      "Epoch 195/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5729 - accuracy: 0.7407 - val_loss: 0.5611 - val_accuracy: 0.7519\n",
      "Epoch 196/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5729 - accuracy: 0.7407 - val_loss: 0.5610 - val_accuracy: 0.7519\n",
      "Epoch 197/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5729 - accuracy: 0.7407 - val_loss: 0.5610 - val_accuracy: 0.7519\n",
      "Epoch 198/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5729 - accuracy: 0.7407 - val_loss: 0.5610 - val_accuracy: 0.7519\n",
      "Epoch 199/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5728 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 200/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5728 - accuracy: 0.7407 - val_loss: 0.5610 - val_accuracy: 0.7519\n",
      "Epoch 201/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5728 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 202/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5728 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 203/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5728 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 204/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5728 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 205/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5729 - accuracy: 0.7407 - val_loss: 0.5610 - val_accuracy: 0.7519\n",
      "Epoch 206/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 207/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 208/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5728 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 209/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 210/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 211/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 212/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 213/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 214/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 215/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 216/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 217/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 218/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 219/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 220/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5609 - val_accuracy: 0.7519\n",
      "Epoch 221/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 222/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 223/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 224/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5727 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 226/1000\n",
      "66/66 [==============================] - 8s 115ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 227/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 228/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 229/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 230/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 231/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 232/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5608 - val_accuracy: 0.7519\n",
      "Epoch 233/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 234/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 235/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 236/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 237/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 238/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 239/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 240/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 241/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 242/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 243/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 244/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 245/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 246/1000\n",
      "66/66 [==============================] - 8s 116ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 247/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 248/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 249/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 250/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 251/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 252/1000\n",
      "66/66 [==============================] - 10s 147ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 253/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 254/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 255/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 256/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 257/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 258/1000\n",
      "66/66 [==============================] - 12s 186ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 259/1000\n",
      "66/66 [==============================] - 10s 149ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 260/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 261/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 262/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 263/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 264/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 265/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 266/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 267/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 268/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 269/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 270/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 271/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 272/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 273/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 274/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 275/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 276/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 277/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 278/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 279/1000\n",
      "66/66 [==============================] - 10s 149ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 280/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 282/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 283/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 284/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 285/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 286/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 287/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 288/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 289/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 290/1000\n",
      "66/66 [==============================] - 8s 129ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 291/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 292/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 293/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 294/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 295/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 296/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 297/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 298/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 299/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 300/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 301/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 302/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 303/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 304/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 305/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 306/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 307/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 308/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 309/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 310/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 311/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 312/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 313/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 314/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 315/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 316/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 317/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 318/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 319/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 320/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 321/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 322/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 323/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 324/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 325/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 326/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 327/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 328/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 329/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 330/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 331/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 332/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 333/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 334/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 335/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 336/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 338/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 339/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 340/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 341/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 342/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 343/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 344/1000\n",
      "66/66 [==============================] - 9s 141ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 345/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 346/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 347/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 348/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 349/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 350/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 351/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 352/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 353/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 354/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 355/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 356/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 357/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 358/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 359/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 360/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 361/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 362/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 363/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 364/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 365/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 366/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 367/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 368/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 369/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 370/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 371/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 372/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 373/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 374/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 375/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 376/1000\n",
      "66/66 [==============================] - 9s 142ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 377/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 378/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 379/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 380/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 381/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 382/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 383/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 384/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 385/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 386/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 387/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 388/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 389/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 390/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 391/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 392/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 394/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 395/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 396/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 397/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 398/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 399/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 400/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 401/1000\n",
      "66/66 [==============================] - 8s 129ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 402/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 403/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 404/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 405/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 406/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 407/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 408/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 409/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 410/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 411/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 412/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 413/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 414/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 415/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 416/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 417/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 418/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 419/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 420/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 421/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 422/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 423/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 424/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 425/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 426/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 427/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 428/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 429/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 430/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 431/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 432/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 433/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 434/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 435/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 436/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 437/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 438/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 439/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 440/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 441/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 442/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 443/1000\n",
      "66/66 [==============================] - 10s 144ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 444/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 445/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 446/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 447/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 448/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 450/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 451/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 452/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 453/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 454/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 455/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 456/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 457/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 458/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 459/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 460/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 461/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 462/1000\n",
      "66/66 [==============================] - 8s 116ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 463/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 464/1000\n",
      "66/66 [==============================] - 8s 116ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 465/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 466/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 467/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 468/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 469/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 470/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 471/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 472/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 473/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 474/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 475/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 476/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 477/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 478/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 479/1000\n",
      "66/66 [==============================] - 8s 117ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 480/1000\n",
      "66/66 [==============================] - 8s 116ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 481/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 482/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 483/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 484/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 485/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 486/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 487/1000\n",
      "66/66 [==============================] - 8s 115ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 488/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 489/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 490/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 491/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 492/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 493/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 494/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 495/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 496/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 497/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 498/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 499/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 500/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 501/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 502/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 503/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 504/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 506/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 507/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 508/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 509/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 510/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 511/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 512/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 513/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 514/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 515/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 516/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 517/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 518/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 519/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 520/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 521/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 522/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 523/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 524/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 525/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 526/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 527/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 528/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 529/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 530/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 531/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 532/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 533/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 534/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 535/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 536/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 537/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 538/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 539/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 540/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 541/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 542/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 543/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 544/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 545/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 546/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 547/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 548/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 549/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 550/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 551/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 552/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 553/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 554/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 555/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 556/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 557/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 558/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 559/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 560/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 562/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 563/1000\n",
      "66/66 [==============================] - 10s 146ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 564/1000\n",
      "66/66 [==============================] - 13s 196ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 565/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 566/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 567/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 568/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 569/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 570/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 571/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 572/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 573/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 574/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 575/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 576/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 577/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 578/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 579/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 580/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 581/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 582/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 583/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 584/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 585/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 586/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 587/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 588/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 589/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 590/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 591/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 592/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 593/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 594/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 595/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 596/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 597/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 598/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 599/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 600/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 601/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 602/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 603/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 604/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 605/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 606/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 607/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 608/1000\n",
      "66/66 [==============================] - 10s 144ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 609/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 610/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 611/1000\n",
      "66/66 [==============================] - 9s 141ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 612/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 613/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 614/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 615/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 616/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 618/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 619/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 620/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 621/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 622/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 623/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 624/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 625/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 626/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 627/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 628/1000\n",
      "66/66 [==============================] - 9s 142ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 629/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 630/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 631/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 632/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 633/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 634/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 635/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 636/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 637/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 638/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 639/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 640/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 641/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 642/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 643/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 644/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 645/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 646/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 647/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 648/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 649/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 650/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 651/1000\n",
      "66/66 [==============================] - 9s 142ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 652/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 653/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 654/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 655/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 656/1000\n",
      "66/66 [==============================] - 10s 146ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 657/1000\n",
      "66/66 [==============================] - 10s 147ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 658/1000\n",
      "66/66 [==============================] - 10s 145ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 659/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 660/1000\n",
      "66/66 [==============================] - 9s 142ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 661/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 662/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 663/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 664/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 665/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 666/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 667/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 668/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 669/1000\n",
      "66/66 [==============================] - 10s 148ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 670/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 671/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 672/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 674/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 675/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 676/1000\n",
      "66/66 [==============================] - 8s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 677/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 678/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 679/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 680/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 681/1000\n",
      "66/66 [==============================] - 10s 154ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 682/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 683/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 684/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 685/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 686/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 687/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 688/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 689/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 690/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 691/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 692/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 693/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 694/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 695/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 696/1000\n",
      "66/66 [==============================] - 10s 150ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 697/1000\n",
      "66/66 [==============================] - 10s 151ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 698/1000\n",
      "66/66 [==============================] - 10s 156ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 699/1000\n",
      "66/66 [==============================] - 9s 144ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 700/1000\n",
      "66/66 [==============================] - 9s 143ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 701/1000\n",
      "66/66 [==============================] - 10s 148ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 702/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 703/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 704/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 705/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 706/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 707/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 708/1000\n",
      "66/66 [==============================] - 9s 141ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 709/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 710/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 711/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 712/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 713/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 714/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 715/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 716/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 717/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 718/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 719/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 720/1000\n",
      "66/66 [==============================] - 9s 142ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 721/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 722/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 723/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 724/1000\n",
      "66/66 [==============================] - 10s 144ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 725/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 726/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 727/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 728/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 729/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 730/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 731/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 732/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 733/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 734/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 735/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 736/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 737/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 738/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 739/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 740/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 741/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 742/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 743/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 744/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 745/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 746/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 747/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 748/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 749/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 750/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 751/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 752/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 753/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 754/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 755/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 756/1000\n",
      "66/66 [==============================] - 10s 152ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 757/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 758/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 759/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 760/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 761/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 762/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 763/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 764/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 765/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 766/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 767/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 768/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 769/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 770/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 771/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 772/1000\n",
      "66/66 [==============================] - 8s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 773/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 774/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 775/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 776/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 777/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 778/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 779/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 780/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 781/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 782/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 783/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 784/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 786/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 787/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 788/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 789/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 790/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 791/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 792/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 793/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 794/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 795/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 796/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 797/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 798/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 799/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 800/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 801/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 802/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 803/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 804/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 805/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 806/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 807/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 808/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 809/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 810/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 811/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 812/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 813/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 814/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 815/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 816/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 817/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 818/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 819/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 820/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 821/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 822/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 823/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 824/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 825/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 826/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 827/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 828/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 829/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 830/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 831/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 832/1000\n",
      "66/66 [==============================] - 9s 141ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 833/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 834/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 835/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 836/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 837/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 838/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 839/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 840/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 842/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 843/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 844/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 845/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 846/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 847/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 848/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 849/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 850/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 851/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 852/1000\n",
      "66/66 [==============================] - 9s 138ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 853/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 854/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 855/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 856/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 857/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 858/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 859/1000\n",
      "66/66 [==============================] - 10s 145ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 860/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 861/1000\n",
      "66/66 [==============================] - 10s 147ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 862/1000\n",
      "66/66 [==============================] - 9s 142ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 863/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 864/1000\n",
      "66/66 [==============================] - 10s 145ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 865/1000\n",
      "66/66 [==============================] - 9s 142ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 866/1000\n",
      "66/66 [==============================] - 10s 153ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 867/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 868/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 869/1000\n",
      "66/66 [==============================] - 10s 151ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 870/1000\n",
      "66/66 [==============================] - 10s 149ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 871/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 872/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 873/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 874/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 875/1000\n",
      "66/66 [==============================] - 9s 139ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 876/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 877/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 878/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 879/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 880/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 881/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 882/1000\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 883/1000\n",
      "66/66 [==============================] - 9s 133ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 884/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 885/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 886/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 887/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 888/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 889/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 890/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 891/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 892/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 893/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 894/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 895/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 896/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 898/1000\n",
      "66/66 [==============================] - 8s 118ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 899/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 900/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 901/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 902/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 903/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 904/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 905/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 906/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 907/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 908/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 909/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 910/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 911/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 912/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 913/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 914/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 915/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 916/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 917/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 918/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 919/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 920/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 921/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 922/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 923/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 924/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 925/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 926/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 927/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 928/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 929/1000\n",
      "66/66 [==============================] - 8s 119ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 930/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 931/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 932/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 933/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 934/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 935/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5604 - val_accuracy: 0.7519\n",
      "Epoch 936/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 937/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 938/1000\n",
      "66/66 [==============================] - 8s 121ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 939/1000\n",
      "66/66 [==============================] - 8s 120ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 940/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 941/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 942/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 943/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 944/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 945/1000\n",
      "66/66 [==============================] - 10s 151ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 946/1000\n",
      "66/66 [==============================] - 9s 144ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 947/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 948/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 949/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 950/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 951/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 952/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 953/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 954/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 955/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 956/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 957/1000\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 958/1000\n",
      "66/66 [==============================] - 10s 154ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 959/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 960/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 961/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 962/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 963/1000\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 0.5725 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 964/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 965/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 966/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 967/1000\n",
      "66/66 [==============================] - 8s 122ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 968/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 969/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5607 - val_accuracy: 0.7519\n",
      "Epoch 970/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 971/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 972/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 973/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 974/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 975/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 976/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 977/1000\n",
      "66/66 [==============================] - 9s 130ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 978/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 979/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 980/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 981/1000\n",
      "66/66 [==============================] - 9s 137ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 982/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 983/1000\n",
      "66/66 [==============================] - 8s 128ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 984/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 985/1000\n",
      "66/66 [==============================] - 8s 123ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 986/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 987/1000\n",
      "66/66 [==============================] - 8s 125ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 988/1000\n",
      "66/66 [==============================] - 8s 127ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 989/1000\n",
      "66/66 [==============================] - 8s 124ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 990/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 991/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 992/1000\n",
      "66/66 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 993/1000\n",
      "66/66 [==============================] - 9s 132ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 994/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 995/1000\n",
      "66/66 [==============================] - 9s 134ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 996/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 997/1000\n",
      "66/66 [==============================] - 9s 131ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 998/1000\n",
      "66/66 [==============================] - 8s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5605 - val_accuracy: 0.7519\n",
      "Epoch 999/1000\n",
      "66/66 [==============================] - 8s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Epoch 1000/1000\n",
      "66/66 [==============================] - 9s 129ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5606 - val_accuracy: 0.7519\n",
      "Saved model to disk\n",
      "INFO:tensorflow:Assets written to: CNN.model\\assets\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'02:23:03'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X+01XWd7/Hny8NvfyDgsUscCExmkrx21CM5WWlqczEjZDWWmOU4JWM3Z9SZKLzeppy1Wjna1NTkijEj6MdgOKgwXgrQgns1UbCOBoiBpnHSEsEfwIgIvu8f38/R7fbs/d3n7PP1/Ho91trr7O/n+2N/PgfYLz6fz/eHIgIzM7OuOqinK2BmZn2bg8TMzOriIDEzs7o4SMzMrC4OEjMzq4uDxMzM6uIgMTOzujhIzMysLg4Ss15GGf/btD7Df1nNKpA0V9IjknZJ2iRpZsm6iyU9VLLuhFQ+XtItkrZL2iHpW6n8S5J+WLL/REkhaVBaXi3py5LuBv4LOErSRSWf8aikvy6r3wxJrZKeT/WcJulcSfeXbff3km4r7jdlA52DxKyyR4D3ACOBq4EfShor6VzgS8AngMOADwE7JDUAtwOPAxOBccBNnfi8jwOzgUPTMZ4CPpg+4yLg6yWBNRX4PjAHOBx4L/AYsAyYJOmYkuNeAPygUy036wQHiVkFEXFzRDwRES9HxI+BLcBU4FPAtRGxLjJbI+LxtO7NwJyI2BMReyPirk585IKI2BgR+yPipYj4PxHxSPqMNcBKsmAD+CQwPyJWpfr9PiI2R8SLwI/JwgNJbycLtdu74Vdi1iEHiVkFkj6Rho6elfQscCxwBDCerLdSbjzweETs7+JHbiv7/LMkrZW0M33+B9Lnt39WR3UAWAicL0lkvZzFKWDMCuEgMeuApLcA3wEuBcZExOHABkBkX/hv7WC3bcCE9nmPMnuAESXL/62DbV65FbekocAS4KvAm9LnL0+f3/5ZHdWBiFgL7CPrvZyPh7WsYA4Ss44dTPbFvh1A0kVkPRKAG4HPSjoxnWF1dAqe+4AngWskHSxpmKRT0j6twHslTZA0Ergy5/OHAEPT5++XdBbw5yXrvwtcJOkMSQdJGifpbSXrvw98C9jfyeE1s05zkJh1ICI2Af8M3AP8EfjvwN1p3c3Al4F/B3YBtwGjI+IAMB04Gvgd0AZ8NO2zimzu4kHgfnLmLCJiF/C3wGLgGbKexbKS9feRJuCB54A1wFtKDvEDsuBzb8QKJz/Yyqz/kTSc7KyvEyJiS0/Xx/o390jM+qdPA+scIvZG6GhS0Mz6MEmPkU3Kn9PDVbEBwkNbZmZWFw9tmZlZXQbE0NYRRxwREydO7OlqmJn1Kffff//TEdGYt92ACJKJEyeyfv36nq6GmVmfIunxWrbz0JaZmdXFQWJmZnVxkJiZWV0GxBxJR1566SXa2trYu3dvT1elUMOGDaOpqYnBgwf3dFXMrJ8asEHS1tbGoYceysSJE8nutt3/RAQ7duygra2NSZMm9XR1zKyfGrBDW3v37mXMmDH9NkQAJDFmzJh+3+sys541YIME6Nch0m4gtNHMetaAHdqqxcsvB0/veZGXX+7pmtTn+Rde4msrH+7paphZD5h5QhOTjji40M9wkFSxZ99+/vBcMcNCzz/3HD+57WY+euGnOrXfZz5xLl/51xs5bOTImvfZtXc///rzbfkbmlm/c8JbRjlIeoO3Nh7CwUO791f12P5nWbpoAV++6rOvKT9w4AANDQ0V9/t/P1vV6c96aNdwfvuVszu9n5lZLRwkVRR5X+S5c+fyyCOP0NzczODBgznkkEMYO3Ysra2tbNq0iXPOOYdt27axd+9eLrvsMmbPng28eruX3bt3c9ZZZ/Hud7+bX/ziF4wbN46lS5cyfPjwAmttZvZ6DhLg6v/cyKYnnn9d+YGXg70vHWD4kAYO6uSk9ZQ3H8YXp7+94vprrrmGDRs20NrayurVqzn77LPZsGHDK6fpzp8/n9GjR/PCCy9w0kkn8eEPf5gxY8a85hhbtmxh0aJFfOc73+EjH/kIS5Ys4YILLuhUPc3M6uUg6SWmTp36mms9vvnNb3LrrbcCsG3bNrZs2fK6IJk0aRLNzc0AnHjiiTz22GNvWH3NzNo5SKBiz+H5F17isR17OLrxEEZ08xxJuYMPfnUybPXq1dxxxx3cc889jBgxgtNOO63Da0GGDh36yvuGhgZeeOGFQutoZtaRAX0dSU869NBD2bVrV4frnnvuOUaNGsWIESPYvHkza9eufYNrZ2ZWu0KDRNI0SQ9L2ippbgfr50hqTa8Nkg5IGl2yvkHSryTdXlI2WtIqSVvSz1FFtiH70O4/5JgxYzjllFM49thjmTNnzmvWTZs2jf3793PcccfxhS98gZNPPrn7K2Bm1k0Ke2a7pAbgN8D7gTZgHTArIjZV2H46cEVEnF5S9ndAC3BYRHwwlV0L7IyIa1I4jYqIz1erS0tLS5Q/2Oqhhx7imGOOqdqGV4a2jjyEEUP67ihgLW01Mysn6f6IaMnbrsgeyVRga0Q8GhH7gJuAGVW2nwUsal+Q1AScDdxYtt0MYGF6vxA4p9tqbGZmnVZkkIwDSi+nbktlryNpBDANWFJS/C/A54DyG5S8KSKeBEg/j6xwzNmS1ktav3379q61wMzMchUZJB3NLFQaR5sO3B0ROwEkfRB4KiLu7+qHR8QNEdESES2NjR0/u76oYb3eZCC00cx6VpFB0gaML1luAp6osO15lAxrAacAH5L0GNmQ2OmSfpjW/VHSWID086muVG7YsGHs2LGjX3/Rtj+PZNiwYT1dFTPrx4qcQV4HTJY0Cfg9WVicX76RpJHAqcArl2RHxJXAlWn9acBnI6J9/TLgQuCa9HNpVyrX1NREW1sb1Ya99r50gKd37yOeGcqQQX3zTOn2JySamRWlsCCJiP2SLgVWAA3A/IjYKOmStH5e2nQmsDIi9tR46GuAxZI+CfwOOLcr9Rs8eHDuUwPv2PRHLl62nv+89N0c01T73XbNzAaSQs9pjYjlwPKysnllywuABVWOsRpYXbK8Azij+2pZWf8d9DIz6z59c7zGzMx6DQdJDfy0WjOzyhwkVfTnM7rMzLqLg8TMzOriIKnC/REzs3wOEjMzq4uDpAaebDczq8xBUoXn2s3M8jlIaqAinmxlZtZPOEiqcpfEzCyPg8TMzOriIKmBJ9vNzCpzkFThyXYzs3wOkhq4R2JmVpmDpAp3SMzM8jlIzMysLg6SGvg6EjOzyhwkVXiy3cwsn4OkBp5sNzOrzEFSRXi63cwsl4PEzMzqUmiQSJom6WFJWyXN7WD9HEmt6bVB0gFJoyUNk3SfpAckbZR0dck+zZLWpn3WS5paZBsAT7WbmVVRWJBIagCuB84CpgCzJE0p3SYirouI5ohoBq4E1kTETuBF4PSIeAfQDEyTdHLa7Vrg6rTPP6TlQniy3cwsX5E9kqnA1oh4NCL2ATcBM6psPwtYBBCZ3al8cHq1f60HcFh6PxJ4orsrbmZmtRtU4LHHAdtKltuAd3a0oaQRwDTg0pKyBuB+4Gjg+oi4N626HFgh6atkQfiuCsecDcwGmDBhQpca0J5cPmvLzKyyInskHX39Vhosmg7cnYa1sg0jDqThqyZgqqRj06pPA1dExHjgCuC7HR0wIm6IiJaIaGlsbOxyI8zMrLoig6QNGF+y3ETlYajzSMNa5SLiWWA1WY8F4ELglvT+ZrIhtIK5S2JmVkmRQbIOmCxpkqQhZGGxrHwjSSOBU4GlJWWNkg5P74cDZwKb0+on0vYApwNbimpAeLbdzCxXYXMkEbFf0qXACqABmB8RGyVdktbPS5vOBFZGxJ6S3ccCC9M8yUHA4oi4Pa27GPiGpEHAXtI8iJmZ9YwiJ9uJiOXA8rKyeWXLC4AFZWUPAsdXOOZdwIndWc88nmw3M6vMV7abmVldHCQ1cIfEzKwyB0kVnms3M8vnIDEzs7o4SGogz7abmVXkIKnCzyMxM8vnIKmB+yNmZpU5SKrwZLuZWT4HiZmZ1cVBUgPPtZuZVeYgqcJDW2Zm+RwkNZCn283MKnKQVOEOiZlZPgeJmZnVxUFSA0+2m5lV5iCpwk9INDPL5yAxM7O6OEiqcH/EzCyfg8TMzOriIKmBJ9vNzCpzkFTjsS0zs1yFBomkaZIelrRV0twO1s+R1JpeGyQdkDRa0jBJ90l6QNJGSVeX7fc36bgbJV1bZBvS5xX9EWZmfdagog4sqQG4Hng/0Aask7QsIja1bxMR1wHXpe2nA1dExE5l39ynR8RuSYOBuyT9JCLWSnofMAM4LiJelHRkUW3wg63MzPIV2SOZCmyNiEcjYh9wE1kAVDILWAQQmd2pfHB6tX+rfxq4JiJeTNs+VUTlzcysNkUGyThgW8lyWyp7HUkjgGnAkpKyBkmtwFPAqoi4N636E+A9ku6VtEbSSRWOOVvSeknrt2/fXldDPLBlZlZZkUHS0fdvpbGi6cDdEbHzlQ0jDkREM9AETJV0bFo1CBgFnAzMARarg0mMiLghIloioqWxsbFLDfCF7WZm+YoMkjZgfMlyE/BEhW3PIw1rlYuIZ4HVZD2W9uPekoa/7gNeBo7ojgpX4rl2M7PKigySdcBkSZMkDSELi2XlG0kaCZwKLC0pa5R0eHo/HDgT2JxW3wacntb9CTAEeLrAdpiZWRWFnbUVEfslXQqsABqA+RGxUdIlaf28tOlMYGVE7CnZfSywMJ35dRCwOCJuT+vmA/MlbQD2ARdGQXdX9MiWmVm+woIEICKWA8vLyuaVLS8AFpSVPQgcX+GY+4ALurOeefyERDOzynxlexWebDczy+cgMTOzujhIauCztszMKqspSCQtkXS2pAEVPL5FiplZvlqD4dvA+cAWSddIeluBdep13CExM6uspiCJiDsi4mPACcBjwCpJv5B0UbqpYr/kyXYzs3w1D1VJGgP8JfAp4FfAN8iCZVUhNTMzsz6hputIJN0CvA34ATA9Ip5Mq34saX1Rles1PLZlZlZRrRckfisiftbRioho6cb69Coe2TIzy1fr0NYx7fe+ApA0StL/LKhOvY6vbDczq6zWILk43YUXgIh4Bri4mCr1Ip5tNzPLVWuQHFT6zI90M8UhxVTJzMz6klrnSFaQPUBqHtnUwSXATwurVS/jK9vNzCqrNUg+D/w12fPSBawEbiyqUr2FB7bMzPLVFCQR8TLZ1e3fLrY6vZM7JGZmldV6Hclk4CvAFGBYe3lEHFVQvXoFz7WbmeWrdbL9e2S9kf3A+4Dvk12caGZmA1ytQTI8Iu4EFBGPR8SXSM9NHwjk2XYzs4pqnWzfm24hvyU9h/33wJHFVat3KOhR8GZm/UqtPZLLgRHA3wInkj0z/cKiKtXbuD9iZlZZbo8kXXz4kYiYA+wGLiq8Vr2E+yNmZvlyeyQRcQA4UV2YKJA0TdLDkrZKmtvB+jmSWtNrg6QDkkZLGibpPkkPSNoo6eoO9v2spJB0RGfrZWZm3afWOZJfAUsl3QzsaS+MiFsq7ZB6MtcD7wfagHWSlkXEppL9rwOuS9tPB66IiJ0ptE6PiN3pwVl3SfpJRKxN245Px/1dJ9raZZ5rNzOrrNYgGQ3s4LVnagVQMUiAqcDWiHgUQNJNwAxgU4XtZwGLACKb5d6dygenV+lI09eBzwFLa6x/l3iu3cwsX61XtndlXmQcsK1kuQ14Z0cbShoBTAMuLSlrAO4Hjgauj4h7U/mHgN9HxAPVRtskzQZmA0yYMKEL1S85lqfbzcwqqvXK9u/RwdxzRPxVtd06KKv0f/zpwN0RsbPk2AeA5vQclFslHQs8ClwF/HlenSPiBuAGgJaWli71LdwhMTPLV+vQ1u0l74cBM4EncvZpA8aXLDdV2ec80rBWuYh4VtJqsh7LCmAS0N4baQJ+KWlqRPwhpz5mZlaAWoe2lpQuS1oE3JGz2zpgsqRJZBcwngecX76RpJHAqWTXprSXNQIvpRAZDpwJ/FNE/JqSCyElPQa0RMTTtbSjyzyyZWZWUa09knKTgaoTDxGxP10FvwJoAOZHxEZJl6T189KmM4GVEbGnZPexwMI0T3IQsDgiSntFbwhf2W5mlq/WOZJdvHbK4A9kzyipKiKWA8vLyuaVLS8AFpSVPQgcX8PxJ+Zt0x18+q+ZWWW1Dm0dWnRFzMysb6rpXluSZqa5jPblwyWdU1y1zMysr6j1po1fjIjn2hci4lngi8VUqffxyJaZWWW1BklH23V1or7P8Fy7mVm+WoNkvaSvSXqrpKMkfZ3sqvMBwQ+2MjOrrNYg+RtgH/BjYDHwAvCZoiplZmZ9R61nbe0BXncb+P4ufJMUM7NctZ61tSrd86p9eZSkFcVVq3fxwJaZWWW1Dm0dkc7UAiAinmFAPLO9p2tgZtb71RokL0t65ZYokibim+OamRm1n8J7FdlTCtek5feSnvUxEPikLTOzymqdbP+ppBay8GglezLhC0VWrDdwl8vMLF+tN238FHAZ2fM/WoGTgXt47aN3+y0/IdHMrLJa50guA04CHo+I95HdmXd7YbXqJTzZbmaWr9Yg2RsRewEkDY2IzcCfFlctMzPrK2qdbG9L15HcBqyS9Az5j9rtNzzZbmZWWa2T7TPT2y9J+jkwEvhpYbXqJXxlu5lZvk7fwTci1uRvZWZmA0WtcyQDkifbzczyOUjMzKwuDpIaeLLdzKyyQoNE0jRJD0vaKul1t6GXNEdSa3ptkHRA0mhJwyTdJ+kBSRslXV2yz3WSNkt6UNKtpXclNjOzN15hQSKpAbgeOAuYAsySNKV0m4i4LiKaI6IZuBJYExE7gReB0yPiHUAzME3SyWm3VcCxEXEc8Ju0X6F8ZbuZWWVF9kimAlsj4tGI2AfcBMyosv0sYBFAZHan8sHpFWndyojYn9atJbttSyHCs+1mZrmKDJJxwLaS5bZU9jqSRgDTgCUlZQ2SWoGngFURcW8Hu/4V8JMKx5wtab2k9du39/u7uZiZ9Zgig6Sj8aBK/8WfDtydhrWyDSMOpCGvJmCqpGNfc3DpKmA/8KOODhgRN0RES0S0NDY2dqkBr35WXbubmfVrRQZJGzC+ZLmJyrdVOY80rFUuPZlxNVmPBQBJFwIfBD4WBY4/eWTLzCxfkUGyDpgsaZKkIWRhsax8I0kjgVPJnnHSXtbYfjaWpOHAmcDmtDwN+DzwoYj4rwLr/2od34gPMTProzp9i5RaRcR+SZcCK4AGYH5EbJR0SVo/L206E1gZEXtKdh8LLExnfh0ELI6I29O6bwFDyW4eCbA2Ii4pqh1mZlZdYUECEBHLgeVlZfPKlhcAC8rKHiR75klHxzy6WytZhUe2zMzy+cr2Gsiz7WZmFTlIqvBku5lZPgdJDdwfMTOrzEFiZmZ1cZBU4Sckmpnlc5DUwHPtZmaVOUiq8GS7mVk+B0kNfPqvmVllDhIzM6uLg6QKj2yZmeVzkJiZWV0cJNV4tt3MLJeDJIfn2c3MqnOQmJlZXRwkVXhgy8wsn4Mkh0e2zMyqc5BU4bl2M7N8DhIzM6uLgySHb49iZladg6QK30bezCyfgySH+yNmZtUVGiSSpkl6WNJWSXM7WD9HUmt6bZB0QNJoScMk3SfpAUkbJV1dss9oSaskbUk/RxVVf0+2m5nlKyxIJDUA1wNnAVOAWZKmlG4TEddFRHNENANXAmsiYifwInB6RLwDaAamSTo57TYXuDMiJgN3pmUzM+shRfZIpgJbI+LRiNgH3ATMqLL9LGARQGR2p/LB6dXeP5gBLEzvFwLndHfFS3mu3cysuiKDZBywrWS5LZW9jqQRwDRgSUlZg6RW4ClgVUTcm1a9KSKeBEg/j6xwzNmS1ktav3379i41wCNbZmb5igySjv4vX+m7eTpwdxrWyjaMOJCGvJqAqZKO7cyHR8QNEdESES2NjY2d2fU15Ol2M7OqigySNmB8yXIT8ESFbc8jDWuVi4hngdVkPRaAP0oaC5B+PtUdlTUzs64pMkjWAZMlTZI0hCwslpVvJGkkcCqwtKSsUdLh6f1w4Exgc1q9DLgwvb+wdL/u5rO2zMzyDSrqwBGxX9KlwAqgAZgfERslXZLWz0ubzgRWRsSekt3HAgvTmV8HAYsj4va07hpgsaRPAr8Dzi2qDYAvJDEzy1FYkABExHJgeVnZvLLlBcCCsrIHgeMrHHMHcEZ31rMSX9luZpbPV7bncIfEzKw6B4mZmdXFQVKNR7bMzHI5SHL4ynYzs+ocJFW4Q2Jmls9BksNXtpuZVecgMTOzujhIqghf2m5mlstBksOT7WZm1TlIqnCHxMwsn4MkhzskZmbVOUjMzKwuDpIqPLJlZpbPQZJDnm03M6vKQVKFJ9vNzPI5SHK4P2JmVp2DxMzM6uIgqcJPSDQzy+cgyeOxLTOzqhwkVXiy3cwsn4MkhzskZmbVFRokkqZJeljSVklzO1g/R1Jrem2QdEDSaEnjJf1c0kOSNkq6rGSfZklr0z7rJU0tsg1mZlZdYUEiqQG4HjgLmALMkjSldJuIuC4imiOiGbgSWBMRO4H9wN9HxDHAycBnSva9Frg67fMPadnMzHpIkT2SqcDWiHg0IvYBNwEzqmw/C1gEEBFPRsQv0/tdwEPAuLRdAIel9yOBJwqo+yt8ZbuZWXWDCjz2OGBbyXIb8M6ONpQ0ApgGXNrBuonA8cC9qehyYIWkr5IF4bsqHHM2MBtgwoQJXam/mZnVoMgeSUf/la90HtR04O40rPXqAaRDgCXA5RHxfCr+NHBFRIwHrgC+29EBI+KGiGiJiJbGxsYuNcBPSDQzy1dkkLQB40uWm6g8DHUeaVirnaTBZCHyo4i4pWTVhUD78s1kQ2iF8ciWmVl1RQbJOmCypEmShpCFxbLyjSSNBE4FlpaUiayn8VBEfK1slyfS9gCnA1sKqDvg28ibmdWisDmSiNgv6VJgBdAAzI+IjZIuSevnpU1nAisjYk/J7qcAHwd+Lak1lf2viFgOXAx8Q9IgYC9pHqQo7pCYmVVX5GQ76Yt/eVnZvLLlBcCCsrK7qPAdntad2J31NDOzrvOV7VV4rt3MLJ+DJIevIzEzq67Qoa2+7thxh/Hi/gM9XQ0zs17NQVLFR0+awEdP8sWMZmbVeGjLzMzq4iAxM7O6OEjMzKwuDhIzM6uLg8TMzOriIDEzs7o4SMzMrC4OEjMzq4sGwsObJG0HHu/i7kcAT3djdfoCt3lgcJsHhnra/JaIyH0y4IAIknpIWh8RLT1djzeS2zwwuM0DwxvRZg9tmZlZXRwkZmZWFwdJvht6ugI9wG0eGNzmgaHwNnuOxMzM6uIeiZmZ1cVBYmZmdXGQVCFpmqSHJW2VNLen69MdJI2X9HNJD0naKOmyVD5a0ipJW9LPUSX7XJl+Bw9L+h89V/v6SGqQ9CtJt6flft1mSYdL+g9Jm9Of958NgDZfkf5eb5C0SNKw/tZmSfMlPSVpQ0lZp9so6URJv07rvql6niseEX518AIagEeAo4AhwAPAlJ6uVze0ayxwQnp/KPAbYApwLTA3lc8F/im9n5LaPhSYlH4nDT3dji62/e+AfwduT8v9us3AQuBT6f0Q4PD+3GZgHPBbYHhaXgz8ZX9rM/Be4ARgQ0lZp9sI3Af8GSDgJ8BZXa2TeySVTQW2RsSjEbEPuAmY0cN1qltEPBkRv0zvdwEPkf0DnEH2xUP6eU56PwO4KSJejIjfAlvJfjd9iqQm4GzgxpLifttmSYeRfeF8FyAi9kXEs/TjNieDgOGSBgEjgCfoZ22OiP8L7Cwr7lQbJY0FDouIeyJLle+X7NNpDpLKxgHbSpbbUlm/IWkicDxwL/CmiHgSsrABjkyb9Zffw78AnwNeLinrz20+CtgOfC8N590o6WD6cZsj4vfAV4HfAU8Cz0XESvpxm0t0to3j0vvy8i5xkFTW0XhhvzlXWtIhwBLg8oh4vtqmHZT1qd+DpA8CT0XE/bXu0kFZn2oz2f/MTwC+HRHHA3vIhjwq6fNtTvMCM8iGcN4MHCzpgmq7dFDWp9pcg0pt7Na2O0gqawPGlyw3kXWT+zxJg8lC5EcRcUsq/mPq7pJ+PpXK+8Pv4RTgQ5IeIxuiPF3SD+nfbW4D2iLi3rT8H2TB0p/bfCbw24jYHhEvAbcA76J/t7ldZ9vYlt6Xl3eJg6SydcBkSZMkDQHOA5b1cJ3qls7M+C7wUER8rWTVMuDC9P5CYGlJ+XmShkqaBEwmm6TrMyLiyohoioiJZH+OP4uIC+jfbf4DsE3Sn6aiM4BN9OM2kw1pnSxpRPp7fgbZHGB/bnO7TrUxDX/tknRy+l19omSfzuvpMxB68wv4ANlZTY8AV/V0fbqpTe8m68I+CLSm1weAMcCdwJb0c3TJPlel38HD1HFmR294Aafx6llb/brNQDOwPv1Z3waMGgBtvhrYDGwAfkB2tlK/ajOwiGwO6CWynsUnu9JGoCX9nh4BvkW600lXXr5FipmZ1cVDW2ZmVhcHiZmZ1cVBYmZmdXGQmJlZXRwkZmZWFweJWS8n6bT2Oxab9UYOEjMzq4uDxKybSLpA0n2SWiX9W3r+yW5J/yzpl5LulNSYtm2WtFbSg5JubX9+hKSjJd0h6YG0z1vT4Q8pebbIj+p6doRZN3OQmHUDSccAHwVOiYhm4ADwMeBg4JcRcQKwBvhi2uX7wOcj4jjg1yXlPwKuj4h3kN0n6slUfjxwOdnzJY4iu3+YWa8wqKcrYNZPnAGcCKxLnYXhZDfOexn4cdrmh8AtkkYCh0fEmlS+ELhZ0qHAuIi4FSAi9gKk490XEW1puRWYCNxVfLPM8jlIzLqHgIURceVrCqUvlG1X7Z5E1YarXix5fwD/27VexENbZt3jTuAvJB0JrzxD+y1k/8b+Im1zPnBXRDwHPCPpPan848CayJ4L0ybpnHSMoZJGvKGtMOsC/6/GrBtExCZJ/xtYKekgsjuzfobsgVJvl3Q/8BzZPApkt/qel4LiUeCiVP5x4N8k/WM6xrlvYDPMusR3/zUrkKTdEXFIT9fDrEge2jIzs7q4R2JmZnVxj8TMzOriIDEzs7o4SMzMrC4OEjMzq4uDxMzM6vL8IK4NAAAABklEQVT/AbHgzGW/6W92AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "#DATADIR = \"chest_xray\\\\train\"\n",
    "\n",
    "#CATEGORIES = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "\n",
    "DATADIR = \"C:\\\\Users\\\\Asia\\\\data1\\\\train\"\n",
    "\n",
    "CATEGORIES = [\"diabetic_retinopathy\", \"glaucoma\", \"healthy\"]\n",
    "\n",
    "for category in CATEGORIES :\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "        break\n",
    "    break\n",
    "#print(img_array)\n",
    "#print(img_array.shape)\n",
    "\n",
    "\n",
    "IMG_SIZE = 50\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES :\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try :\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                output = cv2.medianBlur(new_array, 5)\n",
    "                th2 = cv2.adaptiveThreshold(output,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY_INV,7,2)\n",
    "                training_data.append([th2, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = [] \n",
    "y = [] \n",
    "\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "pickle_out = open(\"X1.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y1.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"X1.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y1.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "###########################################\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "X = pickle.load(open(\"X1.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y1.pickle\", \"rb\"))\n",
    "\n",
    "\n",
    "X = X/255.0\n",
    "y = np.array(y)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = model.fit(X, y, batch_size=64, epochs=100, validation_split=0.2)\n",
    "#history = model.fit(X, y, batch_size=16, epochs=40, validation_split=0.2)\n",
    "#history = model.fit(X, y, batch_size=2, epochs=100, validation_split=0.2)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file :\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model.save('CNN.model')\n",
    "print(history.history.keys())\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "#plt.plot(history.history['val_accuracy'])\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "elapsed_time = time.time() - start_time\n",
    "time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
